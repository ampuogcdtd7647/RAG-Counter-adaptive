{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 2.0,
  "eval_steps": 200,
  "global_step": 2500,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.04,
      "grad_norm": 22.875,
      "learning_rate": 9.804000000000001e-06,
      "loss": 2.7865,
      "step": 50
    },
    {
      "epoch": 0.08,
      "grad_norm": 24.125,
      "learning_rate": 9.604000000000002e-06,
      "loss": 2.241,
      "step": 100
    },
    {
      "epoch": 0.12,
      "grad_norm": 17.625,
      "learning_rate": 9.404e-06,
      "loss": 2.1986,
      "step": 150
    },
    {
      "epoch": 0.16,
      "grad_norm": 25.375,
      "learning_rate": 9.204e-06,
      "loss": 2.2224,
      "step": 200
    },
    {
      "epoch": 0.16,
      "eval_loss": 2.1668267250061035,
      "eval_runtime": 360.9829,
      "eval_samples_per_second": 5.54,
      "eval_steps_per_second": 2.77,
      "step": 200
    },
    {
      "epoch": 0.2,
      "grad_norm": 19.75,
      "learning_rate": 9.004e-06,
      "loss": 2.1205,
      "step": 250
    },
    {
      "epoch": 0.24,
      "grad_norm": 16.375,
      "learning_rate": 8.804e-06,
      "loss": 2.1017,
      "step": 300
    },
    {
      "epoch": 0.28,
      "grad_norm": 18.875,
      "learning_rate": 8.604000000000001e-06,
      "loss": 2.1109,
      "step": 350
    },
    {
      "epoch": 0.32,
      "grad_norm": 19.75,
      "learning_rate": 8.404000000000001e-06,
      "loss": 2.1191,
      "step": 400
    },
    {
      "epoch": 0.32,
      "eval_loss": 2.0756943225860596,
      "eval_runtime": 363.3742,
      "eval_samples_per_second": 5.504,
      "eval_steps_per_second": 2.752,
      "step": 400
    },
    {
      "epoch": 0.36,
      "grad_norm": 16.5,
      "learning_rate": 8.204000000000001e-06,
      "loss": 1.9806,
      "step": 450
    },
    {
      "epoch": 0.4,
      "grad_norm": 18.875,
      "learning_rate": 8.004e-06,
      "loss": 2.033,
      "step": 500
    },
    {
      "epoch": 0.44,
      "grad_norm": 16.875,
      "learning_rate": 7.804e-06,
      "loss": 2.0773,
      "step": 550
    },
    {
      "epoch": 0.48,
      "grad_norm": 17.125,
      "learning_rate": 7.604e-06,
      "loss": 2.0184,
      "step": 600
    },
    {
      "epoch": 0.48,
      "eval_loss": 2.025683879852295,
      "eval_runtime": 364.7471,
      "eval_samples_per_second": 5.483,
      "eval_steps_per_second": 2.742,
      "step": 600
    },
    {
      "epoch": 0.52,
      "grad_norm": 17.125,
      "learning_rate": 7.404e-06,
      "loss": 1.99,
      "step": 650
    },
    {
      "epoch": 0.56,
      "grad_norm": 15.4375,
      "learning_rate": 7.204000000000001e-06,
      "loss": 2.0582,
      "step": 700
    },
    {
      "epoch": 0.6,
      "grad_norm": 16.375,
      "learning_rate": 7.004000000000001e-06,
      "loss": 1.9964,
      "step": 750
    },
    {
      "epoch": 0.64,
      "grad_norm": 52.75,
      "learning_rate": 6.804e-06,
      "loss": 2.0777,
      "step": 800
    },
    {
      "epoch": 0.64,
      "eval_loss": 1.9943488836288452,
      "eval_runtime": 364.0398,
      "eval_samples_per_second": 5.494,
      "eval_steps_per_second": 2.747,
      "step": 800
    },
    {
      "epoch": 0.68,
      "grad_norm": 20.625,
      "learning_rate": 6.604000000000001e-06,
      "loss": 1.974,
      "step": 850
    },
    {
      "epoch": 0.72,
      "grad_norm": 18.375,
      "learning_rate": 6.404e-06,
      "loss": 1.9944,
      "step": 900
    },
    {
      "epoch": 0.76,
      "grad_norm": 15.3125,
      "learning_rate": 6.204e-06,
      "loss": 1.9491,
      "step": 950
    },
    {
      "epoch": 0.8,
      "grad_norm": 17.875,
      "learning_rate": 6.004000000000001e-06,
      "loss": 1.9206,
      "step": 1000
    },
    {
      "epoch": 0.8,
      "eval_loss": 1.9772499799728394,
      "eval_runtime": 364.532,
      "eval_samples_per_second": 5.486,
      "eval_steps_per_second": 2.743,
      "step": 1000
    },
    {
      "epoch": 0.84,
      "grad_norm": 16.125,
      "learning_rate": 5.804000000000001e-06,
      "loss": 2.0616,
      "step": 1050
    },
    {
      "epoch": 0.88,
      "grad_norm": 16.375,
      "learning_rate": 5.604000000000001e-06,
      "loss": 1.9811,
      "step": 1100
    },
    {
      "epoch": 0.92,
      "grad_norm": 15.3125,
      "learning_rate": 5.404e-06,
      "loss": 1.9281,
      "step": 1150
    },
    {
      "epoch": 0.96,
      "grad_norm": 17.25,
      "learning_rate": 5.2040000000000005e-06,
      "loss": 1.986,
      "step": 1200
    },
    {
      "epoch": 0.96,
      "eval_loss": 1.9591505527496338,
      "eval_runtime": 364.2941,
      "eval_samples_per_second": 5.49,
      "eval_steps_per_second": 2.745,
      "step": 1200
    },
    {
      "epoch": 1.0,
      "grad_norm": 19.0,
      "learning_rate": 5.004e-06,
      "loss": 1.9633,
      "step": 1250
    },
    {
      "epoch": 1.04,
      "grad_norm": 17.25,
      "learning_rate": 4.804e-06,
      "loss": 1.6987,
      "step": 1300
    },
    {
      "epoch": 1.08,
      "grad_norm": 19.75,
      "learning_rate": 4.604e-06,
      "loss": 1.6511,
      "step": 1350
    },
    {
      "epoch": 1.12,
      "grad_norm": 19.5,
      "learning_rate": 4.4040000000000005e-06,
      "loss": 1.6356,
      "step": 1400
    },
    {
      "epoch": 1.12,
      "eval_loss": 1.9688042402267456,
      "eval_runtime": 363.8653,
      "eval_samples_per_second": 5.497,
      "eval_steps_per_second": 2.748,
      "step": 1400
    },
    {
      "epoch": 1.16,
      "grad_norm": 16.625,
      "learning_rate": 4.204e-06,
      "loss": 1.6451,
      "step": 1450
    },
    {
      "epoch": 1.2,
      "grad_norm": 16.75,
      "learning_rate": 4.004e-06,
      "loss": 1.7099,
      "step": 1500
    },
    {
      "epoch": 1.24,
      "grad_norm": 16.25,
      "learning_rate": 3.8040000000000003e-06,
      "loss": 1.685,
      "step": 1550
    },
    {
      "epoch": 1.28,
      "grad_norm": 17.0,
      "learning_rate": 3.604e-06,
      "loss": 1.6793,
      "step": 1600
    },
    {
      "epoch": 1.28,
      "eval_loss": 1.9706134796142578,
      "eval_runtime": 366.8679,
      "eval_samples_per_second": 5.452,
      "eval_steps_per_second": 2.726,
      "step": 1600
    },
    {
      "epoch": 1.32,
      "grad_norm": 19.5,
      "learning_rate": 3.404e-06,
      "loss": 1.655,
      "step": 1650
    },
    {
      "epoch": 1.3599999999999999,
      "grad_norm": 19.5,
      "learning_rate": 3.2040000000000006e-06,
      "loss": 1.6795,
      "step": 1700
    },
    {
      "epoch": 1.4,
      "grad_norm": 15.9375,
      "learning_rate": 3.0040000000000004e-06,
      "loss": 1.6923,
      "step": 1750
    },
    {
      "epoch": 1.44,
      "grad_norm": 18.75,
      "learning_rate": 2.804e-06,
      "loss": 1.6821,
      "step": 1800
    },
    {
      "epoch": 1.44,
      "eval_loss": 1.9661091566085815,
      "eval_runtime": 366.4301,
      "eval_samples_per_second": 5.458,
      "eval_steps_per_second": 2.729,
      "step": 1800
    },
    {
      "epoch": 1.48,
      "grad_norm": 18.625,
      "learning_rate": 2.6040000000000004e-06,
      "loss": 1.598,
      "step": 1850
    },
    {
      "epoch": 1.52,
      "grad_norm": 20.375,
      "learning_rate": 2.404e-06,
      "loss": 1.6324,
      "step": 1900
    },
    {
      "epoch": 1.56,
      "grad_norm": 21.0,
      "learning_rate": 2.2040000000000004e-06,
      "loss": 1.6669,
      "step": 1950
    },
    {
      "epoch": 1.6,
      "grad_norm": 17.0,
      "learning_rate": 2.004e-06,
      "loss": 1.6373,
      "step": 2000
    },
    {
      "epoch": 1.6,
      "eval_loss": 1.965988039970398,
      "eval_runtime": 366.5912,
      "eval_samples_per_second": 5.456,
      "eval_steps_per_second": 2.728,
      "step": 2000
    },
    {
      "epoch": 1.6400000000000001,
      "grad_norm": 19.25,
      "learning_rate": 1.8040000000000002e-06,
      "loss": 1.6787,
      "step": 2050
    },
    {
      "epoch": 1.6800000000000002,
      "grad_norm": 16.5,
      "learning_rate": 1.604e-06,
      "loss": 1.6931,
      "step": 2100
    },
    {
      "epoch": 1.72,
      "grad_norm": 16.375,
      "learning_rate": 1.404e-06,
      "loss": 1.6145,
      "step": 2150
    },
    {
      "epoch": 1.76,
      "grad_norm": 18.0,
      "learning_rate": 1.204e-06,
      "loss": 1.6464,
      "step": 2200
    },
    {
      "epoch": 1.76,
      "eval_loss": 1.964905023574829,
      "eval_runtime": 366.2059,
      "eval_samples_per_second": 5.461,
      "eval_steps_per_second": 2.731,
      "step": 2200
    },
    {
      "epoch": 1.8,
      "grad_norm": 15.8125,
      "learning_rate": 1.004e-06,
      "loss": 1.6643,
      "step": 2250
    },
    {
      "epoch": 1.8399999999999999,
      "grad_norm": 15.8125,
      "learning_rate": 8.04e-07,
      "loss": 1.6986,
      "step": 2300
    },
    {
      "epoch": 1.88,
      "grad_norm": 17.625,
      "learning_rate": 6.040000000000001e-07,
      "loss": 1.7184,
      "step": 2350
    },
    {
      "epoch": 1.92,
      "grad_norm": 17.5,
      "learning_rate": 4.04e-07,
      "loss": 1.7061,
      "step": 2400
    },
    {
      "epoch": 1.92,
      "eval_loss": 1.9643168449401855,
      "eval_runtime": 366.6937,
      "eval_samples_per_second": 5.454,
      "eval_steps_per_second": 2.727,
      "step": 2400
    },
    {
      "epoch": 1.96,
      "grad_norm": 16.625,
      "learning_rate": 2.0400000000000003e-07,
      "loss": 1.662,
      "step": 2450
    },
    {
      "epoch": 2.0,
      "grad_norm": 18.375,
      "learning_rate": 4e-09,
      "loss": 1.6394,
      "step": 2500
    }
  ],
  "logging_steps": 50,
  "max_steps": 2500,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 2,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 0.0,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
